{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preparación de datos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En primer lugar importamos pandas para poder navegar por el dataset y hacer las transformaciones que consideremos necesarias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "#Importamos los datasets  y los leemos con pandas desde las rutas en las que están los datos.\n",
    "estimar_ = \"Estimar_uh2020.txt\"\n",
    "modelar_ = \"Modelar_uh2020.txt\"\n",
    "estimar = pd.read_csv(estimar_, sep='|')\n",
    "modelar = pd.read_csv(modelar_, sep='|')\n",
    "datos_train=modelar"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La mayor dificultad que presenta el conjunto de datos es el desbalanceo de las clases. Como podemos observar en el resultado del siguiente código, hay una gran desproporción entre la cantidad de filas de unas clases y otras. El modelo debe ser generalista y mostrar buenos resultados para cualquier conjunto de datos, así que asignaremos un mayor peso a las clases con menor número de ocurrencias cuando lo instanciemos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "modelar.groupby(\"CLASE\").count()[\"ID\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cuando evaluemos el modelo, queremos probarlo con un dataset balanceado, ya que si lo hacemos con uno desbalanceado los resultados pueden verse influidos por la frecuencia de aparición de la clase mayoritaria. Por esto, creamos el dataframe \"balanceado\" y lo almacenamos en un fichero, para disponer de él siempre que queramos. Este fichero contiene 150 filas de cada clase y será utilizado como conjunto de datos de test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clases={\"AGRICULTURE\":338,\n",
    "        \"INDUSTRIAL\": 4490,\n",
    "        \"OFFICE\": 1828,\n",
    "        \"OTHER\": 1332,\n",
    "        \"PUBLIC\": 2976,\n",
    "        \"RESIDENTIAL\": 90173,\n",
    "        \"RETAIL\": 2093}\n",
    "\n",
    "aux=modelar\n",
    "for index, line in aux.iterrows():\n",
    "    if clases[line[\"CLASE\"]]>150:\n",
    "        aux = aux.drop(index)\n",
    "        print(modelar.shape)\n",
    "        clases[line[\"CLASE\"]] = clases[line[\"CLASE\"]]-1\n",
    "\n",
    "aux.to_csv(\"balanceado.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "balanceado = pd.read_csv(\"balanceado.csv\",index_col=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Por otra parte vamos a ver en primer lugar valores estadísticos básicos de cada variable para hacernos una idea general y posteriormente veremos si hay valores nulos y donde están estos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Vamos a ver valores estadísticos básicos de las variables para hacernos una idea en general de los datos.\n",
    "modelar.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Queremos saber si hay valores nulos, ya que esto afectará a nuestra predicción.\n",
    "modelar.isnull().any()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hacemos lo mismo con los valores a estimar\n",
    "estimar.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "estimar.isnull().any()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Queremos ver si los valores nulos son únicos de una clase o están repartidos por todas las clases\n",
    "modelar[modelar[\"CADASTRALQUALITYID\"].isnull()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Podemos ver que las filas afectadas con valores nulos son lasmismas para ambas variables \n",
    "estimar[estimar[\"MAXBUILDINGFLOOR\"].isnull()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#La mayoría están en agriculture, con este código vamos a ver la distribución de los valores nulos en las clases\n",
    "modelar[modelar[\"MAXBUILDINGFLOOR\"].isnull()].groupby('CLASE')[\"CLASE\"].count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En su mayoría están en la clase Agriculture,que justamente es la clase de la que menos valores tenemos, por lo que en una primera instancia vamos a intentar no eliminarlos a no ser que no sea posible. \n",
    "Para ello veremos si este valor depende de los demás parámetros para predecirlo y en caso contrario, lo eliminaremos o haremos una reducción de variables para no tenerlo en cuenta."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "modelar[modelar[\"CLASE\"]==\"AGRICULTURE\"].groupby('CADASTRALQUALITYID')['CADASTRALQUALITYID'].count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#Creamos dataframe con los valores que queremos predecir, los nulos\n",
    "agr_predict=modelar[modelar[\"CADASTRALQUALITYID\"].isnull()]\n",
    "#Dataframe con datos para hacer la predicción, los no nulos\n",
    "agr_data=modelar[~modelar[\"CADASTRALQUALITYID\"].isnull()]\n",
    "#separamos datos del target\n",
    "X=agr_data.drop(\"CADASTRALQUALITYID\",axis=1)._get_numeric_data()\n",
    "y=agr_data[\"CADASTRALQUALITYID\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Primero probamos con un árbol de decisión sencillo para ver si obtenemos un resultado decente\n",
    "from sklearn.model_selection import GridSearchCV, cross_validate\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "t = DecisionTreeClassifier(max_depth=5)\n",
    "cross_validate(t, X, y,return_train_score=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Ahora con una regresión\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "logr = Pipeline([('std', StandardScaler()), ('lr', LogisticRegression(max_iter=1000,solver=\"saga\"))])\n",
    "cross_validate(logr, X, y,return_train_score=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "No obtenemos valores aceptables, por lo que vamos a seguir la siguiente estrategia:\n",
    "- Primero entrenaremos mediante grid search varios modelos hasta quedarnos con el mejor, dando el valor 0 a las filas con valor nulo.\n",
    "- Haremos una reducción de variables para no caer en la maldición de la dimensionalidad, de tal modo que eligiremos según un test chi2 las 40 mejores\n",
    "- Seguiremos reduciendo el número de variables hasta que la calidad del modelo se vea comprometida, de este modo, buscamos que las variables con valor nulo no estén entre las más significativas y así no comprometer el dataset eliminando filas o dando valores aleatorios a estas. \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Otro paso importante en el procesamiento previo de los datos es la categorización de las variables no numéricas. En este caso, solamente hay una, \"CADASTRALQUALITYID\", que puede tomar valores numéricos del 0 al 9 junto con los carácteres \"A\", \"B\" y \"C\". "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "encoder = LabelEncoder()\n",
    "#Los relleno como 0 para poder realizar el test, sin embargo esto no tiene problema ya que posteriormente no utilizaremos esta variable para la predicción.\n",
    "#De este modo podemos contar con etsa fila de datos sin necesidad de eliminarla\n",
    "modelar=modelar.fillna(0)#rellenamos nan con 0\n",
    "modelar[\"CADASTRALQUALITYID\"] = modelar[\"CADASTRALQUALITYID\"].astype(str)\n",
    "encoder.fit(modelar[\"CADASTRALQUALITYID\"])#convertimos a valor numérico los valores String\n",
    "modelar[\"CADASTRALQUALITYID\"] = encoder.transform(modelar[\"CADASTRALQUALITYID\"])\n",
    "\n",
    "#Obtengo el dataset balanceado para hacer el test:\n",
    "balanceado = balanceado.fillna(0)\n",
    "balanceado[\"CADASTRALQUALITYID\"] = balanceado[\"CADASTRALQUALITYID\"].astype(str)\n",
    "encoder.fit(balanceado[\"CADASTRALQUALITYID\"])\n",
    "balanceado[\"CADASTRALQUALITYID\"] = encoder.transform(balanceado[\"CADASTRALQUALITYID\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para generar el conjunto de datos de entrenamiento, eliminamos del dataframe \"datos\" las filas contenidas en \"balanceado\", pues no deberíamos testear el modelo con datos utilizados en su entrenamiento. Para asegurarnos que ambos conjuntos son disjuntos, podemos mostrar su forma por pantalla. Podemos observar que el número de filas de \"datos_train\" es igual a la diferencia del número de filas de \"datos\" y \"balanceado\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datos_train = modelar.loc[modelar.index.difference(balanceado.index), ]\n",
    "display(modelar.shape,datos_train.shape,balanceado.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = datos_train.drop(\"CLASE\", axis=1).drop(\"ID\",axis=1)\n",
    "y= datos_train[\"CLASE\"]\n",
    "X_test = balanceado.drop(\"CLASE\", axis=1).drop(\"ID\",axis=1)\n",
    "y_test = balanceado[\"CLASE\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vamos a utilizar un RandomForestClassifier con estos parámetros ya que tras haber buscado varios modelos y parámetros mediante GridSearch este ha sido el mejor. El GridSearch entrenado se puede encontrar en el adjunto GridSearch.joblib. Utilizando un scoring objetivo de \"precision macro\" los parámetros que mejores resultados arrojaron fueron n_estimators=700 y max_depth=50. Además, aprovechamos la posibilidad que ofrece de balancear los diferentes pesos con la opción de class_weight."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#De todos los modelos que hemos probado y todos los parámetros probados mediante GridSearch nos hemos quedado con este modelo como el que mejor resultado nos ha dado.\n",
    "#Este es el resultado con todas las variables\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.model_selection import GridSearchCV, cross_validate\n",
    "\n",
    "\n",
    "\n",
    "rf = RandomForestClassifier(n_estimators=700,max_depth=50,min_samples_leaf=20,min_samples_split=20, criterion=\"entropy\",class_weight='balanced')\n",
    "rf.fit(X,y)\n",
    "print(classification_report(y_test, rf.predict(X_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "def plot_confusion_matrix(cm, classes,\n",
    "                          normalize=False,\n",
    "                          title='Confusion matrix',\n",
    "                          cmap=plt.cm.Blues):\n",
    "    \"\"\"\n",
    "    This function prints and plots the confusion matrix.\n",
    "    Normalization can be applied by setting `normalize=True`.\n",
    "    \"\"\"\n",
    "    if normalize:\n",
    "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "        print(\"Normalized confusion matrix\")\n",
    "    else:\n",
    "        print('Confusion matrix, without normalization')\n",
    "\n",
    "    # print(cm)\n",
    "\n",
    "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "    plt.title(title)\n",
    "    plt.colorbar()\n",
    "    tick_marks = np.arange(len(classes))\n",
    "    plt.xticks(tick_marks, classes, rotation=90)\n",
    "    plt.yticks(tick_marks, classes)\n",
    "\n",
    "    fmt = '.2f' if normalize else 'd'\n",
    "    thresh = cm.max() / 2.\n",
    "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
    "        plt.text(j, i, format(cm[i, j], fmt),\n",
    "                 horizontalalignment=\"center\",\n",
    "                 color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.ylabel('True label')\n",
    "    plt.xlabel('Predicted label')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.metrics import confusion_matrix\n",
    "cnf_matrix = confusion_matrix(y_test, rf.predict(X_test))\n",
    "# Plot normalized confusion matrix\n",
    "fig = plt.figure()\n",
    "fig.set_size_inches(10, 10, forward=True)\n",
    "plot_confusion_matrix(cnf_matrix, classes=np.asarray(np.unique(y_test)), normalize=True,\n",
    "                      title='Normalized confusion matrix')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ahora procedeemos  a hacer una reducción de variables,eligiendo solo 30, de tal modo que si las variables con valor nulo no están entre las más importantes y la calidad no se ve comprometida nos quedaremos con este modelo, ya que será más sencillo y no nos preocuparemos por no tener dichas variables. Como se puede observar en el resultado, no están entre las 30 variables el CADASTRALQUALITY ni el MAXBUILDINGFLOOR, por lo que las variables que antes habíamos rellenado con 0 no afectarán al resultado final y por tanto a la calidad."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.feature_selection import SelectKBest\n",
    "from sklearn.feature_selection import chi2\n",
    "\n",
    "variables=modelar.loc[:, modelar.columns != 'CLASE']\n",
    "targets=modelar[\"CLASE\"]\n",
    "\n",
    "chi2 = SelectKBest(chi2, k=30).fit(variables._get_numeric_data(), targets)\n",
    "for (col, sel) in zip(variables._get_numeric_data().columns.values, chi2.get_support()):\n",
    "    if sel:\n",
    "        print(col)\n",
    "seleccion = chi2.transform(variables._get_numeric_data())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "rf = RandomForestClassifier(n_estimators=700,max_depth=50,class_weight='balanced')\n",
    "estimator= Pipeline([(\"reduccion\",chi2),(\"rf\",rf)])\n",
    "estimator.fit(X,y)\n",
    "print(classification_report(y_test, estimator.predict(X_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Una vez hemos seleccionado ya el modelo, lo aplicaremos a los datos a predecir para posteriormente montar el CSV a entregar."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ID_pred = estimar['ID']\n",
    "estimar = estimar.drop(\"ID\",axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "estimar=estimar.fillna(0)#rellenamos nan con 0\n",
    "estimar[\"CADASTRALQUALITYID\"] = estimar[\"CADASTRALQUALITYID\"].astype(str)\n",
    "encoder.fit(estimar[\"CADASTRALQUALITYID\"])\n",
    "estimar[\"CADASTRALQUALITYID\"] = encoder.transform(estimar[\"CADASTRALQUALITYID\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Clases_pred = estimator.predict(estimar)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Clases_pred = pd.Series(Clases_pred)\n",
    "entrega = pd. concat([ID_pred, Clases_pred], axis=1) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "entrega.columns = ['ID','CLASE']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "entrega"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "entrega.to_csv('_Los pentahos.txt',sep='|')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
